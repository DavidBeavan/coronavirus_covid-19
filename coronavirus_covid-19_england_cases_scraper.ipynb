{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coronavirus (COVID-19) England Cases Scraper\n",
    "## David Beavan @DavidBeavan\n",
    "## Licence: MIT. Sources: see below\n",
    "## Notes\n",
    "* This is liable to break, lots if the official sources change\n",
    "* One problem is that the offical csv data has no date info\n",
    "* We try to fudge it when scraping today and the data looks like yesterday we do not add it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep data\n",
    "# Data is not packaged with code, Will download from sources and save for future runsdata_base_dir = Path('data/secondary_sources')\n",
    "data_base_dir = Path('data/secondary_sources')\n",
    "data_base_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "data_sub_dir = data_base_dir.joinpath('utla_cases_table')\n",
    "data_sub_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "utla_cases_file = data_sub_dir.joinpath('utla_cases.csv')\n",
    "\n",
    "# Load existing data, if present, otherwise start with a blank dataframe\n",
    "if utla_cases_file.exists():\n",
    "    utla_cases_df = pd.read_csv(utla_cases_file, index_col='utla')\n",
    "else:\n",
    "    utla_cases_df = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_data(df, existing_df=None):\n",
    "    # Take date of new column\n",
    "    scrape_date = list(df)[0]\n",
    "\n",
    "    # If we have an existing dataframe we are adding this column to\n",
    "    if existing_df is not None and len(existing_df) > 0:\n",
    "        # If the new data is the same date as existing data\n",
    "        # replace it if different, but if the same to nothing\n",
    "\n",
    "        if scrape_date in existing_df:\n",
    "            if not existing_df[scrape_date].equals(df[scrape_date]):\n",
    "                existing_df[scrape_date] = df[scrape_date]\n",
    "                df = existing_df\n",
    "            else:\n",
    "                df = existing_df\n",
    "        else:\n",
    "            # We do not have this new date in the existing dataframe\n",
    "            # See if this new data matches yesterday's\n",
    "            # This is the case if we scrape early in a day and assume the date is today\n",
    "            # This is all thanks to assuming the data is dated when it is scraped\n",
    "            # We do this because there is no date info in the primary source\n",
    "\n",
    "            scrape_date_object = datetime.date.fromisoformat(scrape_date)\n",
    "            scrape_date_object = scrape_date_object - \\\n",
    "                datetime.timedelta(days=1)\n",
    "            scrape_date_yesterday = scrape_date_object.isoformat()\n",
    "\n",
    "            # If the new data is the same data as yesterday do nothing\n",
    "            # Otherwise add the new data column\n",
    "            if not (scrape_date_yesterday in existing_df.columns and existing_df[scrape_date_yesterday].equals(df[scrape_date])):\n",
    "                existing_df = existing_df.join(df, how='outer')\n",
    "                df = existing_df\n",
    "            else:\n",
    "                df = existing_df\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retired as data now comes as csv\n",
    "\n",
    "# def scrape_page(url, existing_df=None):\n",
    "\n",
    "#     # Fetch url, it is a web page\n",
    "#     r = requests.get(url)\n",
    "#     soup = BeautifulSoup(r.content, 'html.parser')\n",
    "\n",
    "#     # Find paragraph that matches the date of the data\n",
    "#     date_paras = soup.find_all('p', text=re.compile('These data are as of'))\n",
    "#     if len(date_paras) != 1:\n",
    "#         print('Error: too many possible dates')\n",
    "\n",
    "#     date_para = date_paras[0].text\n",
    "\n",
    "#     # Find the date, parse it and keep the iso data format as text\n",
    "#     date_match = re.search('These data are as of .+? on (.+)\\.', date_para)\n",
    "#     date_string = date_match.group(1)\n",
    "#     datetime_object = datetime.datetime.strptime(date_string, '%d  %B %Y')\n",
    "#     scrape_date = datetime_object.date().isoformat()\n",
    "\n",
    "#     # Find the data table and make a dataframe from it\n",
    "#     table = soup.find_all('table')[0]\n",
    "#     df = pd.read_html(str(table), index_col=0)\n",
    "#     df = df[0]\n",
    "\n",
    "#     # Neaten up the dataframe\n",
    "#     df.index.rename('utla', inplace=True)\n",
    "#     df.columns = [scrape_date]\n",
    "\n",
    "#     # Remove those with no location, later datasets do not give awaiting info\n",
    "#     df.drop('Awaiting confirmation', inplace=True, errors='ignore')\n",
    "\n",
    "#     # As of 2020-03-09 The following areas were merged, we will retrospectivaly do this for early data\n",
    "#     df.rename(index={'Cornwall': 'Cornwall and Isles of Scilly',\n",
    "#                      'Hackney': 'Hackney and City of London'}, inplace=True)\n",
    "\n",
    "#     # Add this column to the existing dataframe\n",
    "#     df = add_new_data(df, existing_df)\n",
    "\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove whitespace and thousand seperators\n",
    "def str_to_int(str):\n",
    "    trimmed = str.strip()\n",
    "    intvalue = trimmed.replace(',', '')\n",
    "    return int(intvalue)\n",
    "\n",
    "\n",
    "def scrape_csv(url, existing_df=None, override_date=None):\n",
    "\n",
    "    # Fetch url, it is a csv\n",
    "    df = pd.read_csv(url, index_col='GSS_CD')\n",
    "    df.index.name = 'utla'\n",
    "\n",
    "    # Drop unneeded columns\n",
    "    df.drop(columns=['GSS_NM'], inplace=True)\n",
    "\n",
    "    # 2020-04-05 raw data had spaces and thousand seperators\n",
    "    # convert to int\n",
    "    df['TotalCases'] = df['TotalCases'].apply(str_to_int)\n",
    "\n",
    "    # Set date of data, overriding if needed\n",
    "    if override_date is not None:\n",
    "        df.columns = [override_date]\n",
    "    else:\n",
    "        scrape_date = datetime.date.today().isoformat()\n",
    "        df.columns = [scrape_date]\n",
    "\n",
    "    # Add this column to the existing dataframe\n",
    "    df = add_new_data(df, existing_df)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retired as we have transitioned from text indexes to utla codes when data source moved to csv\n",
    "\n",
    "# def reindex(df):\n",
    "#     # Fetch url of most recent data, it is a csv\n",
    "#     data_df = pd.read_csv(\n",
    "#         'https://www.arcgis.com/sharing/rest/content/items/b684319181f94875a6879bbc833ca3a6/data')\n",
    "\n",
    "#     # Select code and name colmuns\n",
    "#     data_df = data_df[['GSS_CD', 'GSS_NM']]\n",
    "\n",
    "#     # Index on name, to match the dataframe\n",
    "#     data_df.set_index('GSS_NM', inplace=True)\n",
    "#     data_df.index.name = 'utla'\n",
    "\n",
    "#     # Join to dataframe, so we now have code accessable\n",
    "#     df = df.join(data_df)\n",
    "\n",
    "#     # Change index to code\n",
    "#     df.set_index('GSS_CD', inplace=True)\n",
    "#     df.index.name = 'utla'\n",
    "\n",
    "#     # Add in names in index 0\n",
    "#     df.insert(0, 'GSS_NM', data_df.index.tolist())\n",
    "\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Retired as data now comes as csv\n",
    "\n",
    "# 8 March 2020\n",
    "# utla_cases_df = scrape_page('https://web.archive.org/web/20200308150435/https://www.gov.uk/government/publications/coronavirus-covid-19-number-of-cases-in-england/coronavirus-covid-19-number-of-cases-in-england', utla_cases_df)\n",
    "\n",
    "# 9 March 2020\n",
    "# utla_cases_df = scrape_page('https://web.archive.org/web/20200309190503/https://www.gov.uk/government/publications/coronavirus-covid-19-number-of-cases-in-england/coronavirus-covid-19-number-of-cases-in-england', utla_cases_df)\n",
    "\n",
    "# 10 March 2020\n",
    "# utla_cases_df = scrape_page('https://web.archive.org/web/20200310222310/https://www.gov.uk/government/publications/coronavirus-covid-19-number-of-cases-in-england/coronavirus-covid-19-number-of-cases-in-england', utla_cases_df)\n",
    "\n",
    "# 11 March 2020\n",
    "# utla_cases_df = scrape_page('https://web.archive.org/web/20200311173829/https://www.gov.uk/government/publications/coronavirus-covid-19-number-of-cases-in-england/coronavirus-covid-19-number-of-cases-in-england', utla_cases_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More recent case data, not archived, replaced daily, but then that is what we are doing\n",
    "\n",
    "# utla_cases_df = scrape_csv('https://www.arcgis.com/sharing/rest/content/items/b684319181f94875a6879bbc833ca3a6/data', utla_cases_df, '2020-03-14')\n",
    "utla_cases_df = scrape_csv(\n",
    "    'https://www.arcgis.com/sharing/rest/content/items/b684319181f94875a6879bbc833ca3a6/data', utla_cases_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GSS_NM</th>\n",
       "      <th>2020-03-08</th>\n",
       "      <th>2020-03-09</th>\n",
       "      <th>2020-03-10</th>\n",
       "      <th>2020-03-11</th>\n",
       "      <th>2020-03-12</th>\n",
       "      <th>2020-03-13</th>\n",
       "      <th>2020-03-14</th>\n",
       "      <th>2020-03-15</th>\n",
       "      <th>2020-03-16</th>\n",
       "      <th>...</th>\n",
       "      <th>2020-03-31</th>\n",
       "      <th>2020-04-01</th>\n",
       "      <th>2020-04-02</th>\n",
       "      <th>2020-04-03</th>\n",
       "      <th>2020-04-04</th>\n",
       "      <th>2020-04-05</th>\n",
       "      <th>2020-04-06</th>\n",
       "      <th>2020-04-07</th>\n",
       "      <th>2020-04-08</th>\n",
       "      <th>2020-04-09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>utla</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>E06000001</th>\n",
       "      <td>Hartlepool</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>29</td>\n",
       "      <td>33</td>\n",
       "      <td>36</td>\n",
       "      <td>49</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E06000002</th>\n",
       "      <td>Middlesbrough</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>59</td>\n",
       "      <td>74</td>\n",
       "      <td>92</td>\n",
       "      <td>111</td>\n",
       "      <td>126</td>\n",
       "      <td>151</td>\n",
       "      <td>169</td>\n",
       "      <td>196</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E06000003</th>\n",
       "      <td>Redcar and Cleveland</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>43</td>\n",
       "      <td>51</td>\n",
       "      <td>55</td>\n",
       "      <td>64</td>\n",
       "      <td>75</td>\n",
       "      <td>84</td>\n",
       "      <td>100</td>\n",
       "      <td>112</td>\n",
       "      <td>119</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E06000004</th>\n",
       "      <td>Stockton-on-Tees</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>47</td>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "      <td>77</td>\n",
       "      <td>81</td>\n",
       "      <td>108</td>\n",
       "      <td>117</td>\n",
       "      <td>123</td>\n",
       "      <td>143</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E06000005</th>\n",
       "      <td>Darlington</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>45</td>\n",
       "      <td>52</td>\n",
       "      <td>55</td>\n",
       "      <td>77</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         GSS_NM  2020-03-08  2020-03-09  2020-03-10  \\\n",
       "utla                                                                  \n",
       "E06000001            Hartlepool           0           0           0   \n",
       "E06000002         Middlesbrough           0           0           0   \n",
       "E06000003  Redcar and Cleveland           0           0           0   \n",
       "E06000004      Stockton-on-Tees           0           0           0   \n",
       "E06000005            Darlington           0           0           0   \n",
       "\n",
       "           2020-03-11  2020-03-12  2020-03-13  2020-03-14  2020-03-15  \\\n",
       "utla                                                                    \n",
       "E06000001           0           0           0           0           0   \n",
       "E06000002           0           0           0           0           0   \n",
       "E06000003           0           0           0           1           1   \n",
       "E06000004           2           2           2           2           2   \n",
       "E06000005           0           0           0           2           2   \n",
       "\n",
       "           2020-03-16  ...  2020-03-31  2020-04-01  2020-04-02  2020-04-03  \\\n",
       "utla                   ...                                                   \n",
       "E06000001           0  ...          12          15          17          23   \n",
       "E06000002           0  ...          44          59          74          92   \n",
       "E06000003           0  ...          43          51          55          64   \n",
       "E06000004           2  ...          47          60          70          77   \n",
       "E06000005           2  ...          23          24          30          32   \n",
       "\n",
       "           2020-04-04  2020-04-05  2020-04-06  2020-04-07  2020-04-08  \\\n",
       "utla                                                                    \n",
       "E06000001          23          29          33          36          49   \n",
       "E06000002         111         126         151         169         196   \n",
       "E06000003          75          84         100         112         119   \n",
       "E06000004          81         108         117         123         143   \n",
       "E06000005          32          45          52          55          77   \n",
       "\n",
       "           2020-04-09  \n",
       "utla                   \n",
       "E06000001          55  \n",
       "E06000002         213  \n",
       "E06000003         128  \n",
       "E06000004         152  \n",
       "E06000005          95  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview data\n",
    "utla_cases_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GSS_NM        HartlepoolMiddlesbroughRedcar and ClevelandSto...\n",
       "2020-03-08                                                  224\n",
       "2020-03-09                                                  253\n",
       "2020-03-10                                                  309\n",
       "2020-03-11                                                  357\n",
       "2020-03-12                                                  434\n",
       "2020-03-13                                                  535\n",
       "2020-03-14                                                  764\n",
       "2020-03-15                                                  975\n",
       "2020-03-16                                                 1109\n",
       "2020-03-17                                                 1421\n",
       "2020-03-18                                                 2065\n",
       "2020-03-19                                                 2544\n",
       "2020-03-20                                                 3246\n",
       "2020-03-21                                                 3995\n",
       "2020-03-22                                                 4623\n",
       "2020-03-23                                                 5402\n",
       "2020-03-24                                                 6606\n",
       "2020-03-25                                                 7697\n",
       "2020-03-26                                                 9324\n",
       "2020-03-27                                                11772\n",
       "2020-03-28                                                13864\n",
       "2020-03-29                                                15868\n",
       "2020-03-30                                                17901\n",
       "2020-03-31                                                20194\n",
       "2020-04-01                                                23756\n",
       "2020-04-02                                                27199\n",
       "2020-04-03                                                30646\n",
       "2020-04-04                                                33402\n",
       "2020-04-05                                                38053\n",
       "2020-04-06                                                41267\n",
       "2020-04-07                                                44150\n",
       "2020-04-08                                                48765\n",
       "2020-04-09                                                52329\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview data\n",
    "utla_cases_df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('data/secondary_sources_bak/secondary_sources_bak_2020-04-09')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save data\n",
    "utla_cases_df.to_csv(utla_cases_file)\n",
    "\n",
    "# Delete old backup\n",
    "backup_dir = Path('data/secondary_sources_bak/secondary_sources_bak_' +\n",
    "                  datetime.date.today().isoformat())\n",
    "if backup_dir.exists():\n",
    "    shutil.rmtree(backup_dir)\n",
    "\n",
    "# Make new backup\n",
    "shutil.copytree(Path('data/secondary_sources'), backup_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
